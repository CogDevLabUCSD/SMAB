{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Simulate a decision-making optimization strategy with three arms: 30%, 60%, and 90%.\n",
    "\n",
    "#clear\n",
    "ab = ([5,10], [5,10], [5,10]) #prior assumption: 1/3 for each\n",
    "p = [0.3, 0.6, 0.9] #true probability of the arms\n",
    "w_1=0.3 #initial accuracy of execution for the optimal learning rule\n",
    "w_2=1\n",
    "w_3=0.4\n",
    "N = 3 #number of arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing \n",
    "# ab[0][0]\n",
    "# arm1=1\n",
    "# prob = []\n",
    "# ab[arm1][0]/((ab[arm1][0] + ab[arm1][1]))\n",
    "\n",
    "# for i in range(3):\n",
    "# # prob[0]=ab[arm1][0]/((ab[arm1][0] + ab[arm1][1]))\n",
    "#     prob=np.append(prob,ab[arm1][0]/((ab[arm1][0] + ab[arm1][1])))\n",
    "# prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def det_range_w1(rand,decision_list):\n",
    "    # determine which range that rand falls into\n",
    "    counter=0\n",
    "    if rand >=decision_list[0] and rand <decision_list[1]:\n",
    "        counter=0\n",
    "    elif rand >=decision_list[1] and rand <decision_list[2]:\n",
    "        counter=1\n",
    "    elif rand >=decision_list[2] and rand <=decision_list[3]:\n",
    "        counter=2\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# when w=0.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((4, 100))#create empty matrix\n",
    "\n",
    "for trial in range(100):\n",
    "    post_prob = []\n",
    "    P_D = np.zeros((1,3))\n",
    "    for arm1 in range(3):\n",
    "        post_prob=np.append(post_prob,ab[arm1][0]/((ab[arm1][0] + ab[arm1][1])))\n",
    "\n",
    "        \n",
    "    # calcualte the suboptimal decision rule\n",
    "    Nmax = sum((post_prob == max(post_prob)))\n",
    "    # In case all arms have the same probability\n",
    "    if Nmax == N:\n",
    "        P_D = post_prob\n",
    "    else:\n",
    "        for arm in range(3):\n",
    "            if post_prob[arm] == max(post_prob):\n",
    "                P_D[arm] = w_1/Nmax\n",
    "            else:\n",
    "                P_D[arm] = (1 - w_1)/(N-Nmax)        \n",
    "#     print(\"P_D value: \",P_D)   \n",
    "\n",
    "\n",
    "    # A decision-result(either 0,1, or 2) is made based on the prob of choosing \n",
    "    # each ice hole, based on the suboptimal decision rule\n",
    "    # decisions return in the variable: result\n",
    "    decision_range = np.cumsum([P_D]) # need edit for decision\n",
    "    decision_list=np.append([0],decision_range) #[0.         0.33333333 0.66666667 1.        ]\n",
    "    rand=round(random.uniform(0, 1),1)\n",
    "    result=det_range_w1(rand,decision_list)\n",
    "#     print(result)\n",
    "  \n",
    "    # reward outcome\n",
    "    reward=np.random.multinomial(1,[p[result],1-p[result]])\n",
    "#     print(reward)\n",
    "    \n",
    "    new_1=ab[result][0]+reward[0]\n",
    "    new_2=ab[result][1]+reward[1]\n",
    "    \n",
    "  \n",
    "    # store in data\n",
    "    data[0][trial] = trial\n",
    "    data[1][trial] = result * 30\n",
    "    data[2][trial] = reward[0]\n",
    "    data[3][trial] = sum(data[2,1:trial]) # didn't change, not sure what that is\n",
    "    \n",
    "#     w = w + (0.4/100)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# when w=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = np.zeros((4, 100))#create empty matrix\n",
    "\n",
    "for trial2 in range(100):\n",
    "    post_prob = []\n",
    "    P_D = np.zeros((1,3))\n",
    "    for arm1 in range(3):\n",
    "        post_prob=np.append(post_prob,ab[arm1][0]/((ab[arm1][0] + ab[arm1][1])))\n",
    "\n",
    "        \n",
    "    # calcualte the suboptimal decision rule\n",
    "    Nmax = sum((post_prob == max(post_prob)))\n",
    "    # In case all arms have the same probability\n",
    "    if Nmax == N:\n",
    "        P_D = post_prob\n",
    "    else:\n",
    "        for arm in range(3):\n",
    "            if post_prob[arm] == max(post_prob):\n",
    "                P_D[arm] = w_2/Nmax\n",
    "            else:\n",
    "                P_D[arm] = (1 - w_2)/(N-Nmax)        \n",
    "#     print(\"P_D value: \",P_D)   \n",
    "\n",
    "\n",
    "    # A decision-result(either 0,1, or 2) is made based on the prob of choosing \n",
    "    # each ice hole, based on the suboptimal decision rule\n",
    "    # decisions return in the variable: result\n",
    "    decision_range = np.cumsum([P_D]) # need edit for decision\n",
    "    decision_list=np.append([0],decision_range) #[0.         0.33333333 0.66666667 1.        ]\n",
    "#     print(decision_list)\n",
    "    rand=round(random.uniform(0, 1),1)#randomnize a float betw 0-1\n",
    "    result=det_range_w1(rand,decision_list)\n",
    "#     print(result)\n",
    "  \n",
    "    # reward outcome\n",
    "    reward=np.random.multinomial(1,[p[result],1-p[result]])\n",
    "#     print(reward)\n",
    "    \n",
    "    new_1=ab[result][0]+reward[0]\n",
    "    new_2=ab[result][1]+reward[1]\n",
    "    \n",
    "    data2[0][trial2] = trial2\n",
    "    data2[1][trial2] = result * 30\n",
    "    data2[2][trial2] = reward[0]\n",
    "    data2[3][trial2] = sum(data2[2,1:trial2]) # didn't change, not sure what that is\n",
    "\n",
    "#print(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# when w=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = np.zeros((4, 100))#create empty matrix\n",
    "\n",
    "for trial3 in range(100):\n",
    "    post_prob = []\n",
    "    P_D = np.zeros((1,3))\n",
    "    for arm1 in range(3):\n",
    "        post_prob=np.append(post_prob,ab[arm1][0]/((ab[arm1][0] + ab[arm1][1])))\n",
    "\n",
    "        \n",
    "    # calcualte the suboptimal decision rule\n",
    "    Nmax = sum((post_prob == max(post_prob)))\n",
    "    # In case all arms have the same probability\n",
    "    if Nmax == N:\n",
    "        P_D = post_prob\n",
    "    else:\n",
    "        for arm in range(3):\n",
    "            if post_prob[arm] == max(post_prob):\n",
    "                P_D[arm] = w_3/Nmax\n",
    "            else:\n",
    "                P_D[arm] = (1 - w_3)/(N-Nmax)        \n",
    "#     print(\"P_D value: \",P_D)   \n",
    "\n",
    "\n",
    "    # A decision-result(either 0,1, or 2) is made based on the prob of choosing \n",
    "    # each ice hole, based on the suboptimal decision rule\n",
    "    # decisions return in the variable: result\n",
    "    decision_range = np.cumsum([P_D]) # need edit for decision\n",
    "    decision_list=np.append([0],decision_range) #[0.         0.33333333 0.66666667 1.        ]\n",
    "#     print(decision_list)\n",
    "    rand=round(random.uniform(0, 1),1)#randomnize a float betw 0-1\n",
    "    result=det_range_w1(rand,decision_list)\n",
    "#     print(result)\n",
    "  \n",
    "    # reward outcome\n",
    "    reward=np.random.multinomial(1,[p[result],1-p[result]])\n",
    "#     print(reward)\n",
    "    \n",
    "    new_1=ab[result][0]+reward[0]\n",
    "    new_2=ab[result][1]+reward[1]\n",
    "    \n",
    "    data3[0][trial3] = trial3\n",
    "    data3[1][trial3] = result * 30\n",
    "    data3[2][trial3] = reward[0]\n",
    "    data3[3][trial3] = sum(data3[2,1:trial3]) # didn't change, not sure what that is\n",
    "#print(data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data[3])\n",
    "#print(data2[3])\n",
    "#print(data3[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[3]\n",
    "data_lst = data[3].tolist()\n",
    "x = list(range(1, 101))\n",
    "plt.title('reward score with data')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('reward score')\n",
    "plt.plot(x,data_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[3]\n",
    "data_2st = data2[3].tolist()\n",
    "x = list(range(1, 101))\n",
    "plt.title('reward score with data2')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('reward score')\n",
    "plt.plot(x,data_2st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3[3]\n",
    "data_3st = data3[3].tolist()\n",
    "x = list(range(1, 101))\n",
    "plt.title('reward score with data3')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('reward score')\n",
    "plt.plot(x,data_3st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('reward score with data')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('reward score')\n",
    "plt.plot(x,data_lst, color = 'r' )\n",
    "plt.plot(x,data_2st, color = 'y')\n",
    "plt.plot(x,data_3st, color = 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=pd.read_csv('j01.csv')\n",
    "df_2=pd.read_csv('j02.csv')\n",
    "df_3=pd.read_csv('j03.csv')\n",
    "data_origin_1 = df_1.iloc[3].tolist()\n",
    "#print(data_origin_1)\n",
    "data_origin_2 = df_2.iloc[3].tolist()\n",
    "#print(data_origin_2)\n",
    "data_origin_3 = df_3.iloc[3].tolist()\n",
    "#print(data_origin_3)\n",
    "x = list(range(1, 101)) # for singer \n",
    "x = list(range(1, 201))\n",
    "plt.title('original reward score')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('reward score')\n",
    "plt.plot(x,data_origin_1,color = 'g')\n",
    "plt.plot(x,data_origin_2,color = 'c')\n",
    "plt.plot(x,data_origin_3,color = 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(1, 101))\n",
    "plt.title('reward score with c14 c16 c17') #change\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('reward score')\n",
    "plt.plot(x,data_lst, color = 'r' ,label = 'data1_weighted w = 0.3')\n",
    "plt.plot(x,data_2st, color = 'y',label = 'data2_weighted w = 1')\n",
    "plt.plot(x,data_3st, color = 'b',label = 'data3_weighted w = 0.4')\n",
    "plt.plot(x,data_origin_1,color = 'g', label = 'c14_origin') #change\n",
    "plt.plot(x,data_origin_2,color = 'c', label = 'c16_origin')\n",
    "plt.plot(x,data_origin_3,color = 'm', label = 'c17_origin')\n",
    "plt.legend()\n",
    "plt.savefig('c14c16c17.pdf')  #change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(y):\n",
    "    x = list(range(1, 101))\n",
    "    y = data[3].tolist() #change dataset\n",
    "    plt.title('reward score with data')\n",
    "    plt.xlabel('Trial')\n",
    "    plt.ylabel('reward score')\n",
    "    plt.plot(x,y, color = 'r' ,label = 'data_weighted')\n",
    "    plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
